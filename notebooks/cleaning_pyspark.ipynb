{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d1bc816",
   "metadata": {},
   "source": [
    "#### Import Libraries and initialize Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f1892b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JAVA_HOME = /opt/homebrew/opt/openjdk@17/libexec/openjdk.jdk/Contents/Home\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"JAVA_HOME =\", os.environ.get(\"JAVA_HOME\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c36b484",
   "metadata": {},
   "source": [
    "#### Verified which Python my notebook is using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20e753ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pernebayarailym/anaconda3/envs/myenv/bin/python\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b286b32",
   "metadata": {},
   "source": [
    "#### Ensured PySpark installs in the same Python environment my notebook is using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76608d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyspark in /Users/pernebayarailym/anaconda3/envs/myenv/lib/python3.9/site-packages (4.0.1)\n",
      "Requirement already satisfied: py4j==0.10.9.9 in /Users/pernebayarailym/anaconda3/envs/myenv/lib/python3.9/site-packages (from pyspark) (0.10.9.9)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "93135554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0.1\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "print(pyspark.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f495a2d9",
   "metadata": {},
   "source": [
    "##### Used these commands to install apache-spark because it couldn't find from homebrew , so I manually set the SPARK_HOME path using the path from the command below:\n",
    "\n",
    "1) brew install apache-spark\n",
    "2) brew --prefix apache-spark\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e157968b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Using incubator modules: jdk.incubator.vector\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "25/09/29 14:26:44 WARN Utils: Your hostname, MacBook-Air--Arailym.local, resolves to a loopback address: 127.0.0.1; using 172.20.10.2 instead (on interface en0)\n",
      "25/09/29 14:26:44 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j2-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/09/29 14:26:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.0.1\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['JAVA_HOME'] = '/opt/homebrew/opt/openjdk@17/libexec/openjdk.jdk/Contents/Home'\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MyApp\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(spark.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ed489a5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'fuunctions' from 'pyspark.sql' (/Users/pernebayarailym/anaconda3/envs/myenv/lib/python3.9/site-packages/pyspark/sql/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SparkSession \n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpyspark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msql\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fuunctions \u001b[38;5;28;01mas\u001b[39;00m F \n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'fuunctions' from 'pyspark.sql' (/Users/pernebayarailym/anaconda3/envs/myenv/lib/python3.9/site-packages/pyspark/sql/__init__.py)"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession \n",
    "from pyspark.sql import fuunctions as F "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76b3d83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ec1160df",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a2d226e9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5081f21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cce207a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b1f907ee",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
